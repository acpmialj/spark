{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c723322f-080d-4d03-b4e9-9e9096f67949",
   "metadata": {},
   "source": [
    "# Operaciones sobre RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac54364-0557-4a90-a998-6c326d27437b",
   "metadata": {},
   "source": [
    "## Algunos datos de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "101535d2-35c3-4774-b8ae-849c48420ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se borra la carpeta y su contenido en la máquina local si existe\n",
    "!rm -rf wordcount/\n",
    "\n",
    "# Se crea la carpeta vacía\n",
    "!mkdir -p wordcount/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5b200926-05ba-439c-8963-841b4e1d2f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wordcount/text0.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordcount/text0.txt\n",
    "Analytics is the discovery, interpretation, and communication of meaningful patterns\n",
    "in data. Especially valuable in areas rich with recorded information, analytics relies\n",
    "on the simultaneous application of statistics, computer programming and operations research\n",
    "to quantify performance.\n",
    "\n",
    "Organizations may apply analytics to business data to describe, predict, and improve business\n",
    "performance. Specifically, areas within analytics include predictive analytics, prescriptive\n",
    "analytics, enterprise decision management, descriptive analytics, cognitive analytics, Big\n",
    "Data Analytics, retail analytics, store assortment and stock-keeping unit optimization,\n",
    "marketing optimization and marketing mix modeling, web analytics, call analytics, speech\n",
    "analytics, sales force sizing and optimization, price and promotion modeling, predictive\n",
    "science, credit risk analysis, and fraud analytics. Since analytics can require extensive\n",
    "computation (see big data), the algorithms and software used for analytics harness the most\n",
    "current methods in computer science, statistics, and mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702dd0b1-4d51-4a89-9620-94393421f199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wordcount/text1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordcount/text1.txt\n",
    "The field of data analysis. Analytics often involves studying past historical data to\n",
    "research potential trends, to analyze the effects of certain decisions or events, or to\n",
    "evaluate the performance of a given tool or scenario. The goal of analytics is to improve\n",
    "the business by gaining knowledge which can be used to make improvements or changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "344a20eb-004c-458b-9c71-840c1b08793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wordcount/text2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile wordcount/text2.txt\n",
    "Data analytics (DA) is the process of examining data sets in order to draw conclusions\n",
    "about the information they contain, increasingly with the aid of specialized systems\n",
    "and software. Data analytics technologies and techniques are widely used in commercial\n",
    "industries to enable organizations to make more-informed business decisions and by\n",
    "scientists and researchers to verify or disprove scientific models, theories and\n",
    "hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262c1c09-092f-4227-9720-b2fb05030022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea la carpeta /tmp/wordcount en el HDFS\n",
    "!hdfs dfs -mkdir /tmp/wordcount\n",
    "\n",
    "# copia los archvios del directorio local wordcount/\n",
    "# al directorio /tmp/wordcount/ en el hdfs\n",
    "!hdfs dfs -copyFromLocal wordcount/* /tmp/wordcount/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e91a9a7-b26f-4080-a54e-4c0c20977046",
   "metadata": {},
   "source": [
    "## Preparamos el entorno de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff643166-1d72-48b6-9c23-b30cf53fe2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/21 15:44:51 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# findspark permite usar pyspark (interfaz de Python a Spark),\n",
    "# desde cualquier programa escrito en Python.\n",
    "#\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "#\n",
    "# A continuación se inicializan las variables obligatorias\n",
    "# requeridas para trabajar con Spark desde Python:\n",
    "#\n",
    "#  SparkContext representa la conexión al cluster de Spark.\n",
    "#  SparkConf representa la configuración particular de una aplicación\n",
    "#     escrita en Spark.\n",
    "#  SparkSession representa la conexión para trabajar con SQL.\n",
    "#\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sparkConf = SparkConf().setAppName(\"My SparkQL Application\")\n",
    "# sc.stop()\n",
    "sc = SparkContext(conf=sparkConf)\n",
    "sc.setLogLevel(\"WARN\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f267b-f7a6-4dc8-ba6d-4ed84b516d54",
   "metadata": {},
   "source": [
    "## Trabajamos con RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2aec88ef-3e7a-4111-b400-b3bd2615bd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[2] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Creamos un RDD a partir de una lista\n",
    "#\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "\n",
    "#\n",
    "# Un RDD es un objeto en memoria que gestiona la lista, no la lista como tal\n",
    "#\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd9d6102-bf72-4715-8ce7-eb5bad2a3099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Para ver la lista usamos collect()\n",
    "#\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60434a89-3e64-434b-b2ef-0aeaaf62380d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Creamos un RDD a partir de un diccionario\n",
    "#\n",
    "rdd = sc.parallelize({\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4})\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e5f6060-b099-4de6-bd4f-9b4e2ff93b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Creamos una secuencia de parejas clave-valor. Empezamos por las claves\n",
    "#\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "\n",
    "#\n",
    "# Una vez se tiene un objeto RDD, es posible aplicar operaciones\n",
    "# en paralelo sobre él. En la siguiente línea de código, se aplica\n",
    "# la función lambda x:(x, x**2) a cada elemento del RDD, mediante\n",
    "# la función map. Como resultado se genera una secuencia de pares\n",
    "# [(1, 1), (2, 4), ..., (5, 25)]\n",
    "#\n",
    "rdd = rdd.map(lambda x: (x, x**2))\n",
    "\n",
    "#\n",
    "# Guardamos la secuencia en HDFS, en formato \"SequenceFile\"\n",
    "#\n",
    "rdd.saveAsSequenceFile(\"/tmp/out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd38e902-c3e7-4f27-8d4f-af1b20b6ab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   1 root supergroup          0 2022-11-21 15:51 /tmp/out/_SUCCESS\n",
      "-rw-r--r--   1 root supergroup        124 2022-11-21 15:51 /tmp/out/part-00000\n",
      "-rw-r--r--   1 root supergroup        140 2022-11-21 15:51 /tmp/out/part-00001\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# El archivo se almacena en /tmp/out/. Aquí se usa\n",
    "# ls para listar los archivos de la carpeta /tmp/ del HDFS\n",
    "# Como resultado de la operación anterior, se ha creado la carpeta\n",
    "# /tmp/out\n",
    "#\n",
    "!hdfs dfs -ls /tmp/out/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5bc2436-a5e7-4308-bbe7-8588ea53b129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Una vez se tiene una secuencia de pares almacenada en el hdfs,\n",
    "# es posible volverla a cargar mediante sequenceFile().\n",
    "#\n",
    "sc.sequenceFile(\"/tmp/out\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a740998-5e77-4957-8370-0ea98b2a34b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /tmp/out\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Limpiamos el HDFS\n",
    "#\n",
    "!hdfs dfs -rm -r -f /tmp/out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1df830-91a8-4e81-bc71-5d70eb9fdfbc",
   "metadata": {},
   "source": [
    "## Trabajo con textFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "173c6270-031e-4cdd-ba85-af767d9b377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/tmp/wordcount/ MapPartitionsRDD[18] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# textFile() puede leer un archivo de texto o los archivos\n",
    "# especificados. A continuación, se leen todos los archivos\n",
    "# de texto de la carpeta /tmp/wordcount/ en el hdfs\n",
    "#\n",
    "rdd = sc.textFile(\"/tmp/wordcount/\")\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad667c93-2997-4bd1-ac52-6732c8de7965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Se obtiene el timpo de dato almacenado en la variable rdd\n",
    "#\n",
    "type(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a26b76e-c130-4723-b88c-0d8439e5f494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Analytics is the discovery, interpretation, and communication of meaningful patterns',\n",
       " 'in data. Especially valuable in areas rich with recorded information, analytics relies',\n",
       " 'on the simultaneous application of statistics, computer programming and operations research',\n",
       " 'to quantify performance.',\n",
       " '',\n",
       " 'Organizations may apply analytics to business data to describe, predict, and improve business',\n",
       " 'performance. Specifically, areas within analytics include predictive analytics, prescriptive',\n",
       " 'analytics, enterprise decision management, descriptive analytics, cognitive analytics, Big',\n",
       " 'Data Analytics, retail analytics, store assortment and stock-keeping unit optimization,',\n",
       " 'marketing optimization and marketing mix modeling, web analytics, call analytics, speech',\n",
       " 'analytics, sales force sizing and optimization, price and promotion modeling, predictive',\n",
       " 'science, credit risk analysis, and fraud analytics. Since analytics can require extensive',\n",
       " 'computation (see big data), the algorithms and software used for analytics harness the most',\n",
       " 'current methods in computer science, statistics, and mathematics.',\n",
       " 'The field of data analysis. Analytics often involves studying past historical data to',\n",
       " 'research potential trends, to analyze the effects of certain decisions or events, or to',\n",
       " 'evaluate the performance of a given tool or scenario. The goal of analytics is to improve',\n",
       " 'the business by gaining knowledge which can be used to make improvements or changes.',\n",
       " 'Data analytics (DA) is the process of examining data sets in order to draw conclusions',\n",
       " 'about the information they contain, increasingly with the aid of specialized systems',\n",
       " 'and software. Data analytics technologies and techniques are widely used in commercial',\n",
       " 'industries to enable organizations to make more-informed business decisions and by',\n",
       " 'scientists and researchers to verify or disprove scientific models, theories and',\n",
       " 'hypotheses.']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# rdd almacena como strings, el contenido de los archivos\n",
    "# text0.txt, text1.txt y text2.txt.\n",
    "# Se combinan todos los ficheros .txt, el resultado es una lista de registros de una línea cada uno\n",
    "#\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7625beb2-9a65-479d-8ea1-775e9e6261e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hdfs://0.0.0.0:9000/tmp/wordcount/text0.txt', 'Analytics is the discovery, interpretation, and communication of meaningful patterns\\nin data. Especially valuable in areas rich with recorded information, analytics relies\\non the simultaneous application of statistics, computer programming and operations research\\nto quantify performance.\\n\\nOrganizations may apply analytics to business data to describe, predict, and improve business\\nperformance. Specifically, areas within analytics include predictive analytics, prescriptive\\nanalytics, enterprise decision management, descriptive analytics, cognitive analytics, Big\\nData Analytics, retail analytics, store assortment and stock-keeping unit optimization,\\nmarketing optimization and marketing mix modeling, web analytics, call analytics, speech\\nanalytics, sales force sizing and optimization, price and promotion modeling, predictive\\nscience, credit risk analysis, and fraud analytics. Since analytics can require extensive\\ncomputation (see big data), the algorithms and software used for analytics harness the most\\ncurrent methods in computer science, statistics, and mathematics.\\n')\n",
      "----\n",
      "('hdfs://0.0.0.0:9000/tmp/wordcount/text1.txt', 'The field of data analysis. Analytics often involves studying past historical data to\\nresearch potential trends, to analyze the effects of certain decisions or events, or to\\nevaluate the performance of a given tool or scenario. The goal of analytics is to improve\\nthe business by gaining knowledge which can be used to make improvements or changes.\\n')\n",
      "----\n",
      "('hdfs://0.0.0.0:9000/tmp/wordcount/text2.txt', 'Data analytics (DA) is the process of examining data sets in order to draw conclusions\\nabout the information they contain, increasingly with the aid of specialized systems\\nand software. Data analytics technologies and techniques are widely used in commercial\\nindustries to enable organizations to make more-informed business decisions and by\\nscientists and researchers to verify or disprove scientific models, theories and\\nhypotheses.\\n')\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# A diferencia de TextFile(), que combina varios ficheros en uno y lee por líneas,\n",
    "# wholeTextFiles() devuelve tantos registros como ficheros, y cada registro contiene\n",
    "# todo el texto de cada uno de los ficheros. En este caso, 3 ficheros --> tres registros <clave, valor>\n",
    "# donde clave=identificador del fichero, valor=contenido.\n",
    "#\n",
    "rdd = sc.wholeTextFiles(\"/tmp/wordcount/\")\n",
    "for row in rdd.collect():\n",
    "    print(row)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de4c2df1-2652-4a7e-9073-dc5c065411cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 86, 91, 24, 0, 93, 92, 90, 87, 88, 88, 89, 91, 65, 85, 87, 89, 84, 86, 84, 86, 82, 80, 11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Carga de los archivos.\n",
    "#\n",
    "rdd = sc.textFile(\"/tmp/wordcount/\")\n",
    "\n",
    "#\n",
    "# Calculo de la longitud de cada línea usando la función len().\n",
    "# Se aplica la función len() a cada elemento del rdd. Como se ha leído con textFile()\n",
    "# se aplica a cada línea del texto\n",
    "#\n",
    "rdd = rdd.map(len)\n",
    "print(rdd.collect())\n",
    "\n",
    "#\n",
    "# Cálculo del total de caracteres, haciendo una reducción sobre la lista de longitudes\n",
    "#\n",
    "rdd = rdd.reduce(lambda a, b: a + b)\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0535e958-b273-462e-b833-52886ac4a8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 86, 91, 24, 0, 93, 92, 90, 87, 88, 88, 89, 91, 65, 85, 87, 89, 84, 86, 84, 86, 82, 80, 11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# En este ejemplo se pasa una función arbitraria a `map`.\n",
    "# La función add es equivalente a `lambda a, b: a+b`\n",
    "# Del manual de Python: \"The operator module exports a set\n",
    "# of efficient functions corresponding to the intrinsic operators of Python\"\n",
    "#\n",
    "\n",
    "from operator import add\n",
    "\n",
    "rdd = sc.textFile(\"/tmp/wordcount/\")\n",
    "rdd = rdd.map(len)\n",
    "print(rdd.collect())\n",
    "rdd = rdd.reduce(add)\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "40b0dd42-3ef3-4ab6-834f-1c9a8aedcd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 1), ('a', 1), ('c', 1), ('d', 1), ('a', 1), ('b', 1)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# creación de parejas (key, value). Se desea\n",
    "# contar el número de ocurrencias de cada letra\n",
    "# en la siguiente lista.\n",
    "#\n",
    "rdd = sc.parallelize([\"a\", \"b\", \"a\", \"c\", \"d\", \"a\", \"b\"])\n",
    "\n",
    "##\n",
    "# Se crean las parejas <clave, valor>\n",
    "##\n",
    "rdd = rdd.map(lambda s: (s, 1))\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f2b3b5e-4495-4193-a3e8-8fb5e5ce0c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', 2), ('c', 1), ('d', 1), ('a', 3)]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Se reducen las parejas con la misma clave, sumando\n",
    "# los valores.\n",
    "#\n",
    "rdd = rdd.reduceByKey(lambda a, b: a + b)\n",
    "print(rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "256adc75-dac7-4ec9-bd1d-f0c00cac0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Generamos un fichero \"data.txt\" con líneas con registros, separados por espacios\n",
    "#\n",
    "\n",
    "!rm data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7aff3711-b564-4db7-973d-aef07970b15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile data.txt\n",
    "E   1       b,g,f   jjj:3,bbb:0,ddd:9,ggg:8,hhh:2\n",
    "A   2       a,f,c   ccc:2,ddd:0,aaa:3,hhh:9\n",
    "B   5       f,e,a,c ddd:2,ggg:5,ccc:6,jjj:1\n",
    "A   3       a,b     hhh:9,iii:5,eee:7,bbb:1\n",
    "C   6       f,g,d,a iii:6,ddd:5,eee:4,jjj:3\n",
    "A   7       c,d     bbb:2,hhh:0,ccc:4,fff:1,aaa:7\n",
    "A   9       g,d,a   aaa:5,fff:8,ddd:2,iii:0,jjj:7,ccc:1\n",
    "B   1       b,a     fff:3,hhh:1,ddd:2\n",
    "E   2       d,e,a,f eee:4,ccc:5,iii:9,fff:7,ggg:6,bbb:0\n",
    "B   3       d,b,g,f bbb:7,jjj:9,fff:5,iii:4,ggg:2,eee:3\n",
    "C   7       d,c,f,b hhh:6,eee:4,iii:0,fff:2,jjj:1\n",
    "C   5       d,e,a,c bbb:7,iii:6,ggg:9\n",
    "D   3       g,e,f,b bbb:9,aaa:3,ccc:6,fff:4,eee:2\n",
    "E   8       c,f     aaa:8,ddd:5,jjj:1\n",
    "B   9       d,b     ccc:0,jjj:6,fff:7,ddd:3,aaa:2\n",
    "D   1       f,e     ccc:0,eee:6,bbb:9,ddd:3\n",
    "E   3       e,b,f   bbb:6,iii:3,hhh:5,fff:4,ggg:9,ddd:2\n",
    "D   5       g,a     hhh:4,jjj:5,ccc:9\n",
    "E   8       e,c,f,a ccc:1,iii:6,fff:9\n",
    "E   9       e,a     bbb:9,aaa:3,fff:1\n",
    "E   7       e,f     ddd:9,iii:2,aaa:4\n",
    "E   3       c,b,g   ccc:5,fff:8,iii:7\n",
    "D   5       c,f,a   eee:3,jjj:2,ddd:7\n",
    "A   1       f,a,d   jjj:1,ggg:0,ccc:7,ddd:9,bbb:3\n",
    "E   4       c,d     jjj:6,ccc:0,aaa:1,hhh:9,iii:7,ggg:8\n",
    "E   6       e,d,c   fff:3,eee:6,iii:4,bbb:7,ddd:0,ccc:1\n",
    "A   8       a,e,f   fff:0,ddd:5,ccc:4\n",
    "E   5       c,a,g   ggg:6,hhh:3,ddd:9,ccc:0,jjj:7\n",
    "A   6       f,e     hhh:6,jjj:0,eee:5,iii:7,ccc:3\n",
    "C   0       f,c,a,g eee:1,fff:4,aaa:2,ccc:7,ggg:0,ddd:6\n",
    "A   1       b,f     ccc:6,aaa:9,eee:5,ddd:0,bbb:3\n",
    "D   2       b,f     bbb:7,hhh:1,aaa:6,iii:4,fff:9,ddd:5\n",
    "E   5       a,c     fff:3,ccc:1,ggg:2,eee:5\n",
    "B   4       b,f,c   iii:7,ggg:3,ddd:0,jjj:8,hhh:5,ccc:1\n",
    "B   6       f,a,e   hhh:6,ccc:3,jjj:0,bbb:8,ddd:7\n",
    "D   7       a,f     aaa:0,fff:5,ddd:3\n",
    "B   8       c,a     ddd:5,jjj:2,iii:7,ccc:0,bbb:4\n",
    "C   9       c,a,e,f eee:0,fff:2,hhh:6\n",
    "E   1       e,d     fff:9,iii:2,eee:0\n",
    "E   5       f,a,d   hhh:8,ggg:3,jjj:5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5580fec9-31e3-4947-b144-7f29be8b3f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: `/tmp/data.txt': File exists\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Copia el archivo del sistema local al HDFS\n",
    "# \n",
    "!hdfs dfs -copyFromLocal data.txt /tmp/data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7f0cb09c-7fdd-4c7d-8216-760bed089d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['E', '1', 'b,g,f', 'jjj:3,bbb:0,ddd:9,ggg:8,hhh:2'],\n",
       " ['A', '2', 'a,f,c', 'ccc:2,ddd:0,aaa:3,hhh:9'],\n",
       " ['B', '5', 'f,e,a,c', 'ddd:2,ggg:5,ccc:6,jjj:1'],\n",
       " ['A', '3', 'a,b', 'hhh:9,iii:5,eee:7,bbb:1'],\n",
       " ['C', '6', 'f,g,d,a', 'iii:6,ddd:5,eee:4,jjj:3'],\n",
       " ['A', '7', 'c,d', 'bbb:2,hhh:0,ccc:4,fff:1,aaa:7'],\n",
       " ['A', '9', 'g,d,a', 'aaa:5,fff:8,ddd:2,iii:0,jjj:7,ccc:1'],\n",
       " ['B', '1', 'b,a', 'fff:3,hhh:1,ddd:2'],\n",
       " ['E', '2', 'd,e,a,f', 'eee:4,ccc:5,iii:9,fff:7,ggg:6,bbb:0'],\n",
       " ['B', '3', 'd,b,g,f', 'bbb:7,jjj:9,fff:5,iii:4,ggg:2,eee:3'],\n",
       " ['C', '7', 'd,c,f,b', 'hhh:6,eee:4,iii:0,fff:2,jjj:1'],\n",
       " ['C', '5', 'd,e,a,c', 'bbb:7,iii:6,ggg:9'],\n",
       " ['D', '3', 'g,e,f,b', 'bbb:9,aaa:3,ccc:6,fff:4,eee:2'],\n",
       " ['E', '8', 'c,f', 'aaa:8,ddd:5,jjj:1'],\n",
       " ['B', '9', 'd,b', 'ccc:0,jjj:6,fff:7,ddd:3,aaa:2'],\n",
       " ['D', '1', 'f,e', 'ccc:0,eee:6,bbb:9,ddd:3'],\n",
       " ['E', '3', 'e,b,f', 'bbb:6,iii:3,hhh:5,fff:4,ggg:9,ddd:2'],\n",
       " ['D', '5', 'g,a', 'hhh:4,jjj:5,ccc:9'],\n",
       " ['E', '8', 'e,c,f,a', 'ccc:1,iii:6,fff:9'],\n",
       " ['E', '9', 'e,a', 'bbb:9,aaa:3,fff:1'],\n",
       " ['E', '7', 'e,f', 'ddd:9,iii:2,aaa:4'],\n",
       " ['E', '3', 'c,b,g', 'ccc:5,fff:8,iii:7'],\n",
       " ['D', '5', 'c,f,a', 'eee:3,jjj:2,ddd:7'],\n",
       " ['A', '1', 'f,a,d', 'jjj:1,ggg:0,ccc:7,ddd:9,bbb:3'],\n",
       " ['E', '4', 'c,d', 'jjj:6,ccc:0,aaa:1,hhh:9,iii:7,ggg:8'],\n",
       " ['E', '6', 'e,d,c', 'fff:3,eee:6,iii:4,bbb:7,ddd:0,ccc:1'],\n",
       " ['A', '8', 'a,e,f', 'fff:0,ddd:5,ccc:4'],\n",
       " ['E', '5', 'c,a,g', 'ggg:6,hhh:3,ddd:9,ccc:0,jjj:7'],\n",
       " ['A', '6', 'f,e', 'hhh:6,jjj:0,eee:5,iii:7,ccc:3'],\n",
       " ['C', '0', 'f,c,a,g', 'eee:1,fff:4,aaa:2,ccc:7,ggg:0,ddd:6'],\n",
       " ['A', '1', 'b,f', 'ccc:6,aaa:9,eee:5,ddd:0,bbb:3'],\n",
       " ['D', '2', 'b,f', 'bbb:7,hhh:1,aaa:6,iii:4,fff:9,ddd:5'],\n",
       " ['E', '5', 'a,c', 'fff:3,ccc:1,ggg:2,eee:5'],\n",
       " ['B', '4', 'b,f,c', 'iii:7,ggg:3,ddd:0,jjj:8,hhh:5,ccc:1'],\n",
       " ['B', '6', 'f,a,e', 'hhh:6,ccc:3,jjj:0,bbb:8,ddd:7'],\n",
       " ['D', '7', 'a,f', 'aaa:0,fff:5,ddd:3'],\n",
       " ['B', '8', 'c,a', 'ddd:5,jjj:2,iii:7,ccc:0,bbb:4'],\n",
       " ['C', '9', 'c,a,e,f', 'eee:0,fff:2,hhh:6'],\n",
       " ['E', '1', 'e,d', 'fff:9,iii:2,eee:0'],\n",
       " ['E', '5', 'f,a,d', 'hhh:8,ggg:3,jjj:5']]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# carga los datos a un RDD desde HDFS\n",
    "#\n",
    "rdd = sc.textFile(\"/tmp/data.txt\")\n",
    "\n",
    "# separa los datos por los espacios\n",
    "rdd = rdd.map(lambda x: x.split())\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "06ad1082-598e-494f-b102-826bf57ce201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 5, 3, 6]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# extrae la segunda columna y la convierte de texto a número\n",
    "# \n",
    "rdd = rdd.map(lambda x: int(x[1]))\n",
    "rdd.collect()[0:5]  # se imprimen los primeros cinco valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "07df1d47-044a-456c-8a77-7596710c1f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "rdd.reduce(add)  # Se reduce sumando los valores. Note que no hay parejas clave-valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "98a31c9d-5154-4cef-b660-ddee85e84959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# El codigo se puede reescribir como:\n",
    "#\n",
    "sc.textFile(\"/tmp/data.txt\").map(lambda x: x.split()).map(lambda x: int(x[1])).reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f4de18f1-0498-43e3-9265-f9dba3f45593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', ['E']),\n",
       " ('2', ['A']),\n",
       " ('5', ['B']),\n",
       " ('3', ['A']),\n",
       " ('6', ['C']),\n",
       " ('7', ['A']),\n",
       " ('9', ['A']),\n",
       " ('1', ['B']),\n",
       " ('2', ['E']),\n",
       " ('3', ['B']),\n",
       " ('7', ['C']),\n",
       " ('5', ['C']),\n",
       " ('3', ['D']),\n",
       " ('8', ['E']),\n",
       " ('9', ['B']),\n",
       " ('1', ['D']),\n",
       " ('3', ['E']),\n",
       " ('5', ['D']),\n",
       " ('8', ['E']),\n",
       " ('9', ['E']),\n",
       " ('7', ['E']),\n",
       " ('3', ['E']),\n",
       " ('5', ['D']),\n",
       " ('1', ['A']),\n",
       " ('4', ['E']),\n",
       " ('6', ['E']),\n",
       " ('8', ['A']),\n",
       " ('5', ['E']),\n",
       " ('6', ['A']),\n",
       " ('0', ['C']),\n",
       " ('1', ['A']),\n",
       " ('2', ['D']),\n",
       " ('5', ['E']),\n",
       " ('4', ['B']),\n",
       " ('6', ['B']),\n",
       " ('7', ['D']),\n",
       " ('8', ['B']),\n",
       " ('9', ['C']),\n",
       " ('1', ['E']),\n",
       " ('5', ['E'])]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga el archivo y lo separa por espacios\n",
    "rdd = sc.textFile(\"/tmp/data.txt\").map(lambda x: x.split())\n",
    "\n",
    "#\n",
    "# Se forman parejas <columna 2, [columna 1]>, puesto que\n",
    "# se desea agrupar por la columna 2. Esto es,\n",
    "# [ (1, E), (2, A), ..., (1, E), (5, E)].\n",
    "#\n",
    "\n",
    "rdd = rdd.map(lambda x: (x[1], [x[0]]))\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bc1041f4-7e30-41e1-b6f6-c2494c28657c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', ['E', 'B', 'D', 'A', 'A', 'E']),\n",
       " ('9', ['A', 'B', 'E', 'C']),\n",
       " ('8', ['E', 'E', 'A', 'B']),\n",
       " ('4', ['E', 'B']),\n",
       " ('0', ['C']),\n",
       " ('2', ['A', 'E', 'D']),\n",
       " ('5', ['B', 'C', 'D', 'D', 'E', 'E', 'E']),\n",
       " ('3', ['A', 'B', 'D', 'E', 'E']),\n",
       " ('6', ['C', 'E', 'A', 'B']),\n",
       " ('7', ['A', 'C', 'E', 'D'])]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# Ahora agrupamos por la clave numérica. El \n",
    "# resultado es una colección <clave, valor> en el que cada valor es una lista\n",
    "#\n",
    "rdd.reduceByKey(add).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "371f62ec-c586-4831-99f8-66422bb3e6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jjj', 'bbb', 'ddd', 'ggg', 'hhh', 'ccc', 'ddd', 'aaa', 'hhh', 'ddd']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga el archivo y lo separa por espacios\n",
    "rdd = sc.textFile(\"/tmp/data.txt\").map(lambda x: x.split())\n",
    "\n",
    "#\n",
    "# Se obtiene un rdd que contenga únicamente la columna 4.\n",
    "#\n",
    "#  ['jjj:3,bbb:0,ddd:9,ggg:8,hhh:2',\n",
    "#  ...\n",
    "#  'hhh:8,ggg:3,jjj:5']\n",
    "#\n",
    "rdd = rdd.map(lambda x: x[3])\n",
    "\n",
    "#\n",
    "# Se parte por la ','. flatMap() genera un nuevo registro\n",
    "# en el rdd por cada valor en la lista retornada por\n",
    "# la función lambda x: x.split(',')\n",
    "#\n",
    "#   ['jjj:3',\n",
    "#    'bbb:0',\n",
    "#    ......\n",
    "#    'ggg:3',\n",
    "#    'jjj:5']\n",
    "#\n",
    "rdd = rdd.flatMap(lambda x: x.split(\",\"))\n",
    "\n",
    "#\n",
    "# Ahora separamos por los ':' y tomamos el primer elemento.\n",
    "#\n",
    "#   ['jjj',\n",
    "#    'bbb',\n",
    "#    .....\n",
    "#    'ggg',\n",
    "#    'jjj']\n",
    "#\n",
    "rdd = rdd.map(lambda x: x.split(\":\")[0])\n",
    "rdd.collect()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f802e0a5-1483-4343-9ba2-880e19e6639e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jjj', 18),\n",
       " ('ccc', 23),\n",
       " ('aaa', 13),\n",
       " ('iii', 18),\n",
       " ('eee', 15),\n",
       " ('bbb', 16),\n",
       " ('ddd', 23),\n",
       " ('ggg', 13),\n",
       " ('hhh', 16),\n",
       " ('fff', 20)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Se aplica el algoritmo de conteo de palabras\n",
    "#\n",
    "rdd = rdd.map(lambda s: (s, 1)).reduceByKey(add)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c4fc4b46-ff28-4544-83ab-9d8e2aaaaa03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['E', 3, 5],\n",
       " ['A', 3, 4],\n",
       " ['B', 4, 4],\n",
       " ['A', 2, 4],\n",
       " ['C', 4, 4],\n",
       " ['A', 2, 5],\n",
       " ['A', 3, 6],\n",
       " ['B', 2, 3],\n",
       " ['E', 4, 6],\n",
       " ['B', 4, 6],\n",
       " ['C', 4, 5],\n",
       " ['C', 4, 3],\n",
       " ['D', 4, 5],\n",
       " ['E', 2, 3],\n",
       " ['B', 2, 5],\n",
       " ['D', 2, 4],\n",
       " ['E', 3, 6],\n",
       " ['D', 2, 3],\n",
       " ['E', 4, 3],\n",
       " ['E', 2, 3],\n",
       " ['E', 2, 3],\n",
       " ['E', 3, 3],\n",
       " ['D', 3, 3],\n",
       " ['A', 3, 5],\n",
       " ['E', 2, 6],\n",
       " ['E', 3, 6],\n",
       " ['A', 3, 3],\n",
       " ['E', 3, 5],\n",
       " ['A', 2, 5],\n",
       " ['C', 4, 6],\n",
       " ['A', 2, 5],\n",
       " ['D', 2, 6],\n",
       " ['E', 2, 4],\n",
       " ['B', 3, 6],\n",
       " ['B', 3, 5],\n",
       " ['D', 2, 3],\n",
       " ['B', 2, 5],\n",
       " ['C', 4, 3],\n",
       " ['E', 2, 3],\n",
       " ['E', 3, 3]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga el archivo y lo separa por espacios\n",
    "rdd = sc.textFile(\"/tmp/data.txt\").map(lambda x: x.split())\n",
    "\n",
    "#\n",
    "# Elimina la columna 2. Queda así:\n",
    "#\n",
    "#   [['E', 'b,g,f', 'jjj:3,bbb:0,ddd:9,ggg:8,hhh:2'],\n",
    "#    ['A', 'a,f,c', 'ccc:2,ddd:0,aaa:3,hhh:9'],\n",
    "#   ....\n",
    "#   ['E', 'e,d', 'fff:9,iii:2,eee:0'],\n",
    "#   ['E', 'f,a,d', 'hhh:8,ggg:3,jjj:5']]\n",
    "#\n",
    "rdd = rdd.map(lambda x: [x[0], x[2], x[3]])\n",
    "\n",
    "#\n",
    "# Parte las columnas 2 y 3 por la coma y cuenta los elementos\n",
    "#\n",
    "rdd = rdd.map(lambda x: [x[0], len(x[1].split(\",\")), len(x[2].split(\",\"))])\n",
    "\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3f155fa4-10cd-4ba1-aff0-883d37f6f629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a', 'aaa'), 5),\n",
       " (('a', 'bbb'), 7),\n",
       " (('a', 'ccc'), 13),\n",
       " (('a', 'ddd'), 13),\n",
       " (('a', 'eee'), 7),\n",
       " (('a', 'fff'), 10),\n",
       " (('a', 'ggg'), 8),\n",
       " (('a', 'hhh'), 8),\n",
       " (('a', 'iii'), 7),\n",
       " (('a', 'jjj'), 10),\n",
       " (('b', 'aaa'), 4),\n",
       " (('b', 'bbb'), 7),\n",
       " (('b', 'ccc'), 5),\n",
       " (('b', 'ddd'), 7),\n",
       " (('b', 'eee'), 5),\n",
       " (('b', 'fff'), 8),\n",
       " (('b', 'ggg'), 4),\n",
       " (('b', 'hhh'), 7),\n",
       " (('b', 'iii'), 7),\n",
       " (('b', 'jjj'), 5),\n",
       " (('c', 'aaa'), 5),\n",
       " (('c', 'bbb'), 4),\n",
       " (('c', 'ccc'), 12),\n",
       " (('c', 'ddd'), 9),\n",
       " (('c', 'eee'), 6),\n",
       " (('c', 'fff'), 8),\n",
       " (('c', 'ggg'), 7),\n",
       " (('c', 'hhh'), 7),\n",
       " (('c', 'iii'), 8),\n",
       " (('c', 'jjj'), 8),\n",
       " (('d', 'aaa'), 4),\n",
       " (('d', 'bbb'), 6),\n",
       " (('d', 'ccc'), 7),\n",
       " (('d', 'ddd'), 5),\n",
       " (('d', 'eee'), 6),\n",
       " (('d', 'fff'), 8),\n",
       " (('d', 'ggg'), 6),\n",
       " (('d', 'hhh'), 4),\n",
       " (('d', 'iii'), 9),\n",
       " (('d', 'jjj'), 8),\n",
       " (('e', 'aaa'), 3),\n",
       " (('e', 'bbb'), 8),\n",
       " (('e', 'ccc'), 9),\n",
       " (('e', 'ddd'), 7),\n",
       " (('e', 'eee'), 7),\n",
       " (('e', 'fff'), 9),\n",
       " (('e', 'ggg'), 4),\n",
       " (('e', 'hhh'), 4),\n",
       " (('e', 'iii'), 8),\n",
       " (('e', 'jjj'), 3),\n",
       " (('f', 'aaa'), 8),\n",
       " (('f', 'bbb'), 10),\n",
       " (('f', 'ccc'), 13),\n",
       " (('f', 'ddd'), 17),\n",
       " (('f', 'eee'), 11),\n",
       " (('f', 'fff'), 11),\n",
       " (('f', 'ggg'), 9),\n",
       " (('f', 'hhh'), 10),\n",
       " (('f', 'iii'), 10),\n",
       " (('f', 'jjj'), 12),\n",
       " (('g', 'aaa'), 3),\n",
       " (('g', 'bbb'), 3),\n",
       " (('g', 'ccc'), 6),\n",
       " (('g', 'ddd'), 5),\n",
       " (('g', 'eee'), 4),\n",
       " (('g', 'fff'), 5),\n",
       " (('g', 'ggg'), 4),\n",
       " (('g', 'hhh'), 3),\n",
       " (('g', 'iii'), 4),\n",
       " (('g', 'jjj'), 6)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga el archivo y lo separa por espacios\n",
    "rdd = sc.textFile(\"/tmp/data.txt\").map(lambda x: x.split())\n",
    "\n",
    "#\n",
    "# Elimina las dos primeras columnas.\n",
    "#\n",
    "# Resultado:\n",
    "#\n",
    "#  [['b,g,f', 'jjj:3,bbb:0,ddd:9,ggg:8,hhh:2'],\n",
    "#   ['a,f,c', 'ccc:2,ddd:0,aaa:3,hhh:9'],\n",
    "#   ...\n",
    "#   ['e,d', 'fff:9,iii:2,eee:0'],\n",
    "#   ['f,a,d', 'hhh:8,ggg:3,jjj:5']]\n",
    "#\n",
    "rdd = rdd.map(lambda x: [x[2], x[3]])\n",
    "\n",
    "#\n",
    "# Expande el dataset generando un registro por cada\n",
    "# elemento de la columna 1.\n",
    "#\n",
    "# Resultado:\n",
    "#\n",
    "#  [['b', 'jjj:3,bbb:0,ddd:9,ggg:8,hhh:2'],\n",
    "#   ['g', 'jjj:3,bbb:0,ddd:9,ggg:8,hhh:2'],\n",
    "#  ...\n",
    "#   ['a', 'hhh:8,ggg:3,jjj:5'],\n",
    "#   ['d', 'hhh:8,ggg:3,jjj:5']]\n",
    "#\n",
    "rdd = rdd.flatMap(lambda x: [[e, x[1]] for e in x[0].split(\",\")])\n",
    "\n",
    "#\n",
    "# Cambia la segunda columna por una lista\n",
    "# partiendo los elementos por las comas\n",
    "##\n",
    "# Resultado:\n",
    "#\n",
    "#  [['b', ['jjj:3', 'bbb:0', 'ddd:9', 'ggg:8', 'hhh:2']],\n",
    "#   ['g', ['jjj:3', 'bbb:0', 'ddd:9', 'ggg:8', 'hhh:2']],\n",
    "#   ....\n",
    "#   ['a', ['hhh:8', 'ggg:3', 'jjj:5']],\n",
    "#   ['d', ['hhh:8', 'ggg:3', 'jjj:5']]]\n",
    "#\n",
    "rdd = rdd.map(lambda x: [x[0], x[1].split(\",\")])\n",
    "\n",
    "#\n",
    "# Parte cada elemento por los ':' y toma el primer elemento\n",
    "#\n",
    "# Resultado:\n",
    "#\n",
    "#    [['b', ['jjj', 'bbb', 'ddd', 'ggg', 'hhh']],\n",
    "#     ['g', ['jjj', 'bbb', 'ddd', 'ggg', 'hhh']],\n",
    "#     ...\n",
    "#     ['a', ['hhh', 'ggg', 'jjj']],\n",
    "#     ['d', ['hhh', 'ggg', 'jjj']]]\n",
    "#\n",
    "rdd = rdd.map(lambda x: [x[0], [a.split(\":\")[0] for a in x[1]]])\n",
    "\n",
    "#\n",
    "# Genera las parejas clave valor.\n",
    "#\n",
    "# Resultado:\n",
    "#\n",
    "#   [(('b', 'jjj'), 1),\n",
    "#    (('b', 'bbb'), 1),\n",
    "#    ...\n",
    "#    (('d', 'ggg'), 1),\n",
    "#    (('d', 'jjj'), 1)]\n",
    "#\n",
    "rdd = rdd.flatMap(lambda x: [((x[0], a), 1) for a in x[1]])\n",
    "\n",
    "#\n",
    "# Reduce por clave para hacer el conteo.\n",
    "# Se usa sortByKey() para ordenas la salida\n",
    "# por claves\n",
    "#\n",
    "rdd.reduceByKey(add).sortByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "12c82234-f6c9-42e1-b8ca-935ed3ae1d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /tmp/wordcount\n",
      "Deleted /tmp/data.txt\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Un poco de limpieza\n",
    "#\n",
    "!hdfs dfs -rm -r -f /tmp/wordcount\n",
    "!hdfs dfs -rm /tmp/data.txt\n",
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1ef64-10c2-4eb7-84ca-e0db96dff93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
